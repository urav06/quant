{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "from quant import Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x = hf_hub_download(repo_id = f\"monster-monash/WISDM\", filename = f\"WISDM_X.npy\", repo_type = \"dataset\")\n",
    "X = np.load(path_x, mmap_mode = \"r\")\n",
    "\n",
    "path_y = hf_hub_download(repo_id = f\"monster-monash/WISDM\", filename = f\"WISDM_y.npy\", repo_type = \"dataset\")\n",
    "y = np.load(path_y, mmap_mode = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m Y_te = le.transform(Y_te)\n\u001b[32m      8\u001b[39m quant = Quant(depth=\u001b[32m6\u001b[39m, div=\u001b[32m4\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X_train_transform = \u001b[43mquant\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_tr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/research/quant/code/quant.py:158\u001b[39m, in \u001b[36mQuant.fit_transform\u001b[39m\u001b[34m(self, X, Y)\u001b[39m\n\u001b[32m    148\u001b[39m     Z = function(X)\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m.models[index] = \\\n\u001b[32m    151\u001b[39m     IntervalModel(\n\u001b[32m    152\u001b[39m         input_length = Z.shape[-\u001b[32m1\u001b[39m],\n\u001b[32m    153\u001b[39m         depth        = \u001b[38;5;28mself\u001b[39m.depth,\n\u001b[32m    154\u001b[39m         div          = \u001b[38;5;28mself\u001b[39m.div\n\u001b[32m    155\u001b[39m     )\n\u001b[32m    157\u001b[39m     features.append(\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    161\u001b[39m \u001b[38;5;28mself\u001b[39m.fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(features, -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/research/quant/code/quant.py:100\u001b[39m, in \u001b[36mIntervalModel.fit_transform\u001b[39m\u001b[34m(self, X, Y)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mself\u001b[39m.fit(X, Y)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/research/quant/code/quant.py:91\u001b[39m, in \u001b[36mIntervalModel.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     86\u001b[39m features = []\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.intervals:\n\u001b[32m     90\u001b[39m     features.append(\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m         \u001b[43mf_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m:\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiv\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiv\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m     92\u001b[39m     )\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(features, -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/research/quant/code/quant.py:58\u001b[39m, in \u001b[36mf_quantile\u001b[39m\u001b[34m(X, div)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X.quantile(torch.tensor([\u001b[32m0.5\u001b[39m]), dim = -\u001b[32m1\u001b[39m).permute(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     quantiles = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_quantiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     quantiles[..., \u001b[32m1\u001b[39m::\u001b[32m2\u001b[39m] = quantiles[..., \u001b[32m1\u001b[39m::\u001b[32m2\u001b[39m] - X.mean(-\u001b[32m1\u001b[39m, keepdims = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m quantiles\n",
      "\u001b[31mRuntimeError\u001b[39m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "X_tr, X_te, Y_tr, Y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_tr = torch.tensor(X_tr.squeeze().astype(np.float32)).unsqueeze(1)\n",
    "X_te = torch.tensor(X_te.squeeze().astype(np.float32)).unsqueeze(1)\n",
    "le = LabelEncoder()\n",
    "Y_tr = le.fit_transform(Y_tr)\n",
    "Y_te = le.transform(Y_te)\n",
    "\n",
    "quant = Quant(depth=6, div=4)\n",
    "X_train_transform = quant.fit_transform(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ExtraTreesClassifier(n_estimators=200, max_features=0.1, criterion='entropy', n_jobs=-1)\n",
    "classifier.fit(X_train_transform, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transform = quant.transform(X_test)\n",
    "predictions = classifier.predict(X_test_transform)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
